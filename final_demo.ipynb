{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3VlObTJ-x6_U"
      },
      "outputs": [],
      "source": [
        "Dataset = \"FB15K\" # WN18 and FB15K\n",
        "Embedding_size = 250 # 25,50,100,200,250\n",
        "Epoch_count = 10 # fix record for 50 , 75 (for fb15k try for 50 75 takes time)\n",
        "Learning_rate = 0.01 # fix\n",
        "\n"
      ],
      "id": "3VlObTJ-x6_U"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rlr-815AX7PX",
        "outputId": "68e2987a-58d7-49d2-a452-59c3e0e46665"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_scatter-2.1.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt21cu121\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_sparse-0.6.18%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.23.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt21cu121\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_cluster-1.6.3%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.23.5)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt21cu121\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (932 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m932.1/932.1 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.2+pt21cu121\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "try:\n",
        "  import torch\n",
        "except:\n",
        "  !pip install torch\n",
        "try:\n",
        "    import torch_geometric\n",
        "except ModuleNotFoundError:\n",
        "    # Installing torch geometric packages with specific CUDA+PyTorch version.\n",
        "    # See https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html for details\n",
        "    TORCH = torch.__version__.split('+')[0]\n",
        "    CUDA = 'cu' + torch.version.cuda.replace('.','')\n",
        "\n",
        "    !pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-geometric\n",
        "    import torch_geometric\n",
        "import torch_geometric.nn as geom_nn\n",
        "import torch_geometric.data as geom_data"
      ],
      "id": "Rlr-815AX7PX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rI1xc6vpDyE2"
      },
      "outputs": [],
      "source": [],
      "id": "rI1xc6vpDyE2"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6btIO9sJDQZN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "Dataset_path = \"/content/drive/MyDrive/DATASETS/\"+ Dataset\n",
        "File_path = Dataset_path + \"/edges_as_text_all.tsv\"\n",
        "df = pd.read_csv(File_path, sep='\\t',header=None  ,names=[\"Subject\",\"Predicate\",\"Object\"])\n",
        "List = df.values.tolist()\n",
        "#File_path = Dataset_path + \"/edges_as_text_valid.tsv\"\n",
        "#df = pd.read_csv(File_path, sep='\\t',header=None  ,names=[\"Subject\",\"Predicate\",\"Object\"])\n",
        "#List = List + df.values.tolist()\n"
      ],
      "id": "6btIO9sJDQZN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0fb733db"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec, KeyedVectors"
      ],
      "id": "0fb733db"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "76f63fc0"
      },
      "outputs": [],
      "source": [
        "num_features = Embedding_size"
      ],
      "id": "76f63fc0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8d6c555b"
      },
      "outputs": [],
      "source": [],
      "id": "8d6c555b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kXrMIHAmo3V6"
      },
      "outputs": [],
      "source": [],
      "id": "kXrMIHAmo3V6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kJMTLNbTpb0h"
      },
      "outputs": [],
      "source": [
        "Word2Vec_embeddings = Word2Vec(List,size=num_features, window=2, min_count=1, workers=4,sg=1)\n"
      ],
      "id": "kJMTLNbTpb0h"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kswDGNH4rf5"
      },
      "source": [],
      "id": "3kswDGNH4rf5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fa71d36a"
      },
      "outputs": [],
      "source": [
        "# reading a map_entity_id_to_text.tsv file and getting vector representation for a entity\n",
        "\n",
        "File_path = Dataset_path + \"/map_entity_id_to_text.tsv\"\n",
        "map_entity_id_to_text_features = pd.read_csv(File_path, sep='\\t',header=None,names=[\"id\",\"entity\"])\n",
        "#print(map_entity_id_to_text_features)\n",
        "map_entity_id_to_text_features.set_index('id', inplace=True)\n",
        "\n",
        "entity_features = []\n",
        "for i in map_entity_id_to_text_features['entity']:\n",
        "  entity_features.append(Word2Vec_embeddings.wv[i])\n",
        "\n",
        "\n",
        "map_entity_id_to_text_features['entity_features'] = entity_features\n",
        "\n",
        "n_entities = len(map_entity_id_to_text_features)\n",
        "\n",
        "map_entity_id_to_text_features.head()"
      ],
      "id": "fa71d36a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1e92c930"
      },
      "outputs": [],
      "source": [
        "# reading a map_entity_id_to_text.tsv file and getting vector representation for a entity\n",
        "\n",
        "File_path = Dataset_path + \"/map_relation_id_to_text.tsv\"\n",
        "map_relation_id_to_text_features = pd.read_csv(File_path, sep='\\t',header=None,names=[\"id\",\"relation\"])\n",
        "map_relation_id_to_text_features.set_index('id', inplace=True)\n",
        "\n",
        "relation_features = []\n",
        "for i in map_relation_id_to_text_features['relation']:\n",
        "    relation_features.append(Word2Vec_embeddings.wv[i])\n",
        "\n",
        "map_relation_id_to_text_features['relation_features'] = relation_features\n",
        "\n",
        "\n",
        "n_relations = len(map_relation_id_to_text_features)\n",
        "\n",
        "map_relation_id_to_text_features"
      ],
      "id": "1e92c930"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bc53aaa4"
      },
      "outputs": [],
      "source": [
        "File_path = Dataset_path + \"/edges_as_id_train.tsv\"\n",
        "\n",
        "Adjacency_list = []\n",
        "\n",
        "edges_as_id_train = pd.read_csv(File_path, sep='\\t',header=None  ,names=[\"Subject\",\"Predicate\",\"Object\"])\n",
        "\n",
        "Adjacency_list = torch.tensor([edges_as_id_train['Subject'],edges_as_id_train['Object']])\n",
        "\n",
        "Adjacency_list"
      ],
      "id": "bc53aaa4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ac325eef"
      },
      "outputs": [],
      "source": [
        "File_path = Dataset_path + \"/edges_as_id_test.tsv\"\n",
        "\n",
        "edges_as_id_test = pd.read_csv(File_path, sep='\\t',header=None  ,names=[\"Subject\",\"Predicate\",\"Object\"])\n"
      ],
      "id": "ac325eef"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hElneCQzKzHf"
      },
      "outputs": [],
      "source": [
        "File_path = Dataset_path + \"/edges_as_id_valid.tsv\"\n",
        "\n",
        "edges_as_id_valid = pd.read_csv(File_path, sep='\\t',header=None  ,names=[\"Subject\",\"Predicate\",\"Object\"])"
      ],
      "id": "hElneCQzKzHf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d0816a6d"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import GATConv\n",
        "import torch\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self,num_features):\n",
        "        super(GAT, self).__init__()\n",
        "        self.conv1 = GATConv(num_features, num_features,edge_dim=num_features)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "\n",
        "\n",
        "        # Message Passing Layer (Transformation)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "\n",
        "        return x"
      ],
      "id": "d0816a6d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8e365011"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "GraphAttentionModel = GAT(num_features).to(device)\n",
        "\n",
        "X = torch.tensor(entity_features)\n",
        "X = X.to(device)\n",
        "\n",
        "Adjacency_list = Adjacency_list.to(device)\n",
        "\n",
        "X_updated = GraphAttentionModel(X, Adjacency_list)"
      ],
      "id": "8e365011"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bc120dec"
      },
      "outputs": [],
      "source": [
        "updated_node_features = X_updated.cpu()\n",
        "updated_node_features = updated_node_features.detach().numpy()"
      ],
      "id": "bc120dec"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5e5078a6"
      },
      "outputs": [],
      "source": [
        "#updated_node_features = entity_features"
      ],
      "id": "5e5078a6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hwHqVqa2ufy1"
      },
      "outputs": [],
      "source": [],
      "id": "hwHqVqa2ufy1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dWhaIg8Puf1c"
      },
      "outputs": [],
      "source": [],
      "id": "dWhaIg8Puf1c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5Gl-ElpDuf4q"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for triplet in edges_as_id_train.values:\n",
        "    h,r,t = triplet[0],triplet[1],triplet[2]\n",
        "    x_train.append(np.concatenate((updated_node_features[h],updated_node_features[t]),axis=None))\n",
        "\n",
        "X_train = sc.fit_transform(x_train)\n",
        "y_train = edges_as_id_train['Predicate'].values\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=n_relations)\n"
      ],
      "id": "5Gl-ElpDuf4q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M44MpQKHKoox"
      },
      "outputs": [],
      "source": [
        "x_valid = []\n",
        "y_valid = []\n",
        "\n",
        "for triplet in edges_as_id_valid.values:\n",
        "    h,r,t = triplet[0],triplet[1],triplet[2]\n",
        "    x_valid.append(np.concatenate((updated_node_features[h],updated_node_features[t]),axis=None))\n",
        "\n",
        "X_valid = sc.fit_transform(x_valid)\n",
        "\n",
        "y_valid = edges_as_id_valid['Predicate'].values\n",
        "y_valid = tf.keras.utils.to_categorical(y_valid, num_classes=n_relations)"
      ],
      "id": "M44MpQKHKoox"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8XTxgViJNF3l"
      },
      "outputs": [],
      "source": [
        "edges_as_id_valid.values"
      ],
      "id": "8XTxgViJNF3l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qiRTqkrTvJuK"
      },
      "outputs": [],
      "source": [
        "saved_model_name = \"Scoring_Model\" + \"_\" + Dataset + \"_ES_\" + str(Embedding_size) + \"_EPC_\" + str(Epoch_count)\n",
        "\n",
        "print(saved_model_name)"
      ],
      "id": "qiRTqkrTvJuK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y6vjF9xE_lU8"
      },
      "outputs": [],
      "source": [
        "def get_hidden_units(input_layer,output_layer,hidden_layers):\n",
        "  hidden_units = []\n",
        "\n",
        "  if input_layer > output_layer :\n",
        "    step = (input_layer - output_layer)/(hidden_layers+1)\n",
        "    current = input_layer - step\n",
        "    for i in range(hidden_layers):\n",
        "      hidden_units.append(int(current))\n",
        "      current = current - step\n",
        "    return hidden_units\n",
        "  else :\n",
        "    return get_hidden_units(output_layer,input_layer,hidden_layers)[::-1]\n"
      ],
      "id": "y6vjF9xE_lU8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Do0y3npwCH22"
      },
      "outputs": [],
      "source": [
        "#get_hidden_units(500,18,4)"
      ],
      "id": "Do0y3npwCH22"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4c16e935"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "\n",
        "from keras.layers import Dense , Dropout\n",
        "from keras.activations import relu, sigmoid\n",
        "from keras.layers import LeakyReLU\n",
        "from keras. models import Sequential\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "Neural_network_model = Sequential()\n",
        "\n",
        "\n",
        "\n",
        "input = 2*Embedding_size\n",
        "output = n_relations\n",
        "\n",
        "hidden_units = get_hidden_units(input,output,4)\n",
        "\n",
        "print(hidden_units)\n",
        "\n",
        "Neural_network_model.add(Dense(hidden_units[0], activation='relu', input_dim= input))                     #input layer\n",
        "\n",
        "#Neural_network_model.add(Dropout(rate=0.5))\n",
        "\n",
        "Neural_network_model.add(Dense(hidden_units[1], activation='relu', input_dim= hidden_units[0]))           #1\n",
        "\n",
        "#Neural_network_model.add(Dropout(rate=0.5))\n",
        "\n",
        "Neural_network_model.add(Dense(hidden_units[2], activation='relu', input_dim= hidden_units[1]))           #2\n",
        "\n",
        "#Neural_network_model.add(Dropout(rate=0.5))\n",
        "\n",
        "Neural_network_model.add(Dense(hidden_units[3], activation='relu', input_dim= hidden_units[2]))           #3\n",
        "\n",
        "#Neural_network_model.add(Dropout(rate=0.5))\n",
        "\n",
        "Neural_network_model.add(Dense(output, activation= 'softmax', input_dim= hidden_units[3]))                #output layer\n",
        "\n",
        "\n",
        "sgd=SGD(learning_rate=Learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "\n",
        "\n",
        "Neural_network_model.summary()\n",
        "\n",
        "Neural_network_model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\"\"\"\n",
        "history = Neural_network_model.fit(X_train,y_train,validation_data=(X_valid,y_valid),epochs=Epoch_count,batch_size=256,shuffle=True)\n",
        "\n",
        "\n",
        "print(history.history)\n",
        "\n",
        "plt.plot(history.history['accuracy'],label=\"accuracy\")\n",
        "\n",
        "plt.plot(history.history['loss'],label=\"loss\")\n",
        "\n",
        "plt.xlabel('Loss')\n",
        "\n",
        "plt.ylabel('Iterations')\n",
        "\n",
        "leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=True, fancybox=True)\n",
        "leg.get_frame().set_alpha(0.5)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "del x_train\n",
        "del y_train\"\"\"\n"
      ],
      "id": "4c16e935"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "02d60cb5"
      },
      "outputs": [],
      "source": [
        "\n",
        "x_test = []\n",
        "y_test = []\n",
        "for triplet in edges_as_id_test.values:\n",
        "    h,r,t = triplet[0],triplet[1],triplet[2]\n",
        "    x_test.append(np.concatenate((updated_node_features[h],updated_node_features[t]),axis=None))\n",
        "\n",
        "X_test = sc.transform(x_test)\n",
        "#print(X_test)\n",
        "\n",
        "#y_test = edges_as_id_train['Predicate'].values\n",
        "#y_test = tf.keras.utils.to_categorical(y_train, num_classes=n_relations)"
      ],
      "id": "02d60cb5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "80454915"
      },
      "outputs": [],
      "source": [],
      "id": "80454915"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "064738d3"
      },
      "outputs": [],
      "source": [],
      "id": "064738d3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1d71827f"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(test):\n",
        "  j = 1\n",
        "  results_c = []\n",
        "  for i in range(1,Epoch_count+1,steps):\n",
        "    Neural_network_model.fit(X_train,y_train,validation_data=(X_valid,y_valid),epochs=steps,batch_size=256,shuffle=True,verbose=False)\n",
        "    pred_y  = Neural_network_model.predict(X_test)\n",
        "    print(\"Epoch Count = \", j * steps)\n",
        "    j+=1\n",
        "    results = evaluation_metrics(edges_as_id_test['Predicate'],pred_y)\n",
        "    #results_c.append(results)\n",
        "    #test.__call__(results[0],Neural_network_model)\n",
        "  return results_c\n"
      ],
      "id": "1d71827f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ImuLs9AWIu3T"
      },
      "outputs": [],
      "source": [
        "#import numpy as np\n",
        "#import torch\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=5, verbose=True, delta=0, path='checkpoint.pt'):\n",
        "\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_mrr = None\n",
        "        self.early_stop = False\n",
        "        self.val_mrr_max = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "\n",
        "    def __call__(self, val_mrr, model):\n",
        "\n",
        "        if self.best_mrr is None:\n",
        "            self.best_mrr = val_mrr\n",
        "            self.save_checkpoint(val_mrr, model)\n",
        "        elif val_mrr < self.best_mrr + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_mrr = val_mrr\n",
        "            self.save_checkpoint(val_mrr, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_mrr, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_mrr_max:.6f} --> {val_mrr:.6f}).  Saving model ...')\n",
        "        #torch.save(model.state_dict(), self.path)\n",
        "        model.save(self.path)\n",
        "        self.val_mrr_max = val_mrr"
      ],
      "id": "ImuLs9AWIu3T"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "64d536ba"
      },
      "outputs": [],
      "source": [
        "def Hit_n(ranks,n):\n",
        "    count = 0\n",
        "    for i in ranks:\n",
        "        if i <= n:\n",
        "            count = count + 1\n",
        "\n",
        "    return count/len(ranks)*100\n",
        "\n",
        "def Mean_rank(ranks):\n",
        "    return sum(ranks)/len(ranks)\n",
        "\n",
        "def Mean_reciprocal_rank(ranks):\n",
        "    total_sum = 0\n",
        "    for i in ranks:\n",
        "        #print(1/i)\n",
        "        total_sum = total_sum + (1/i)\n",
        "\n",
        "    return total_sum/len(ranks)\n",
        "\n",
        "\n",
        "def evaluation_metrics(actual_index_array,predicted_scores_array):\n",
        "    rankings_array = []\n",
        "    ranks = []\n",
        "    count = 0\n",
        "    for scores_array in predicted_scores_array:\n",
        "        score_rankings = list(np.argsort(scores_array)[::-1])\n",
        "        rankings_array.append(score_rankings)\n",
        "\n",
        "        rank = score_rankings.index(actual_index_array[count]) + 1\n",
        "        #print(scores_array,score_rankings,actual_index_array[count],rank)\n",
        "        ranks.append(rank)\n",
        "        count=count+1\n",
        "\n",
        "    print(\"Hit@1 = \"+\"{:.2f}\".format(Hit_n(ranks,1)))\n",
        "\n",
        "    print(\"Hit@3 = \"+\"{:.2f}\".format(Hit_n(ranks,3)))\n",
        "\n",
        "    print(\"Hit@5 = \"+\"{:.2f}\".format(Hit_n(ranks,5)))\n",
        "\n",
        "    print(\"Hit@10 = \"+\"{:.2f}\".format(Hit_n(ranks,10)))\n",
        "\n",
        "    print(\"Mean Rank = \"+\"{:.2f}\".format(Mean_rank(ranks)))\n",
        "\n",
        "    print(\"Mean Reciprocal Rank = \"+\"{:.2f}\".format(Mean_reciprocal_rank(ranks)))\n",
        "\n",
        "    return [Mean_reciprocal_rank(ranks),Mean_rank(ranks),Hit_n(ranks,10),Hit_n(ranks,5),Hit_n(ranks,3),Hit_n(ranks,1)]"
      ],
      "id": "64d536ba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bd3395c2"
      },
      "outputs": [],
      "source": [
        "#evaluation_metrics(edges_as_id_test['Predicate'],pred_y)"
      ],
      "id": "bd3395c2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a7adb5fc"
      },
      "outputs": [],
      "source": [
        "\"\"\"#def evaluate_model():\n",
        "pred_y  = Neural_network_model.predict(X_test)\n",
        "evaluation_metrics(edges_as_id_test,pred_y)\n",
        "\n",
        "\"\"\""
      ],
      "id": "a7adb5fc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "n4Myvz2MJNWe"
      },
      "outputs": [],
      "source": [
        "#evaluate_model()"
      ],
      "id": "n4Myvz2MJNWe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Hc5QM9tq3_U",
        "outputId": "aaa140cd-fd34-4e65-c2b2-81384e101d23"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch Count =  1\n",
            "Hit@1 = 64.44\n",
            "Hit@3 = 89.21\n",
            "Hit@5 = 94.77\n",
            "Hit@10 = 97.71\n",
            "Mean Rank = 4.34\n",
            "Mean Reciprocal Rank = 0.78\n",
            "Epoch Count =  2\n",
            "Hit@1 = 67.71\n",
            "Hit@3 = 91.43\n",
            "Hit@5 = 96.41\n",
            "Hit@10 = 98.61\n",
            "Mean Rank = 3.01\n",
            "Mean Reciprocal Rank = 0.80\n",
            "Epoch Count =  3\n",
            "Hit@1 = 69.12\n",
            "Hit@3 = 92.39\n",
            "Hit@5 = 97.01\n",
            "Hit@10 = 98.94\n",
            "Mean Rank = 2.42\n",
            "Mean Reciprocal Rank = 0.81\n",
            "Epoch Count =  4\n",
            "Hit@1 = 69.03\n",
            "Hit@3 = 92.82\n",
            "Hit@5 = 97.35\n",
            "Hit@10 = 99.09\n",
            "Mean Rank = 2.29\n",
            "Mean Reciprocal Rank = 0.81\n",
            "Epoch Count =  5\n",
            "Hit@1 = 70.02\n",
            "Hit@3 = 93.18\n",
            "Hit@5 = 97.58\n",
            "Hit@10 = 99.20\n",
            "Mean Rank = 2.12\n",
            "Mean Reciprocal Rank = 0.82\n",
            "Epoch Count =  6\n",
            "Hit@1 = 70.91\n",
            "Hit@3 = 93.34\n",
            "Hit@5 = 97.68\n",
            "Hit@10 = 99.24\n",
            "Mean Rank = 2.05\n",
            "Mean Reciprocal Rank = 0.82\n",
            "Epoch Count =  7\n",
            "Hit@1 = 70.37\n",
            "Hit@3 = 93.38\n",
            "Hit@5 = 97.74\n",
            "Hit@10 = 99.32\n",
            "Mean Rank = 2.00\n",
            "Mean Reciprocal Rank = 0.82\n",
            "Epoch Count =  8\n",
            "Hit@1 = 70.92\n",
            "Hit@3 = 93.53\n",
            "Hit@5 = 97.83\n",
            "Hit@10 = 99.35\n",
            "Mean Rank = 1.98\n",
            "Mean Reciprocal Rank = 0.83\n",
            "Epoch Count =  9\n",
            "Hit@1 = 70.90\n",
            "Hit@3 = 93.71\n",
            "Hit@5 = 97.86\n",
            "Hit@10 = 99.40\n",
            "Mean Rank = 1.92\n",
            "Mean Reciprocal Rank = 0.83\n",
            "Epoch Count =  10\n",
            "Hit@1 = 70.97\n",
            "Hit@3 = 93.64\n",
            "Hit@5 = 97.90\n",
            "Hit@10 = 99.43\n",
            "Mean Rank = 1.94\n",
            "Mean Reciprocal Rank = 0.83\n"
          ]
        }
      ],
      "source": [
        "test = EarlyStopping()\n",
        "steps=1\n",
        "results_c = evaluate_model(test)"
      ],
      "id": "8Hc5QM9tq3_U"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lUm45TOX7wlC"
      },
      "outputs": [],
      "source": [],
      "id": "lUm45TOX7wlC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GnJptsLU1VSj"
      },
      "outputs": [],
      "source": [],
      "id": "GnJptsLU1VSj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kNjG9Ihd7woD"
      },
      "outputs": [],
      "source": [],
      "id": "kNjG9Ihd7woD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yDXmEqz27wqp"
      },
      "outputs": [],
      "source": [],
      "id": "yDXmEqz27wqp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xuqsBWV87wtV"
      },
      "outputs": [],
      "source": [],
      "id": "xuqsBWV87wtV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h7zRgIOJ7wwC"
      },
      "outputs": [],
      "source": [],
      "id": "h7zRgIOJ7wwC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ag5tG2a57wys"
      },
      "outputs": [],
      "source": [],
      "id": "ag5tG2a57wys"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}